{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"GTKAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "import string\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S005', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S005\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S010\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S011\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S014\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S022\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S026\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S028\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S029\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S032\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S034\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S035\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S037\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S042\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S044\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S045\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S046\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S050\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S051\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S052\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S053\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S054\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S055\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S056\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S057\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S058\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S059\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S060\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S061\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S062\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S063\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S064\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S065\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S066\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S067\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S068\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S069\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S070\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S071\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S072\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S073\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S074\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S075\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S076\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S077\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S078\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S079\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S080\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S081\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S082\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S083\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S084\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S085\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S086\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S087\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S088\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S089\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S090\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S091\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S092\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S093\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S094\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S095\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S096\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S097\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S098\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S099\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S100\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S101\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S102\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S103\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S104\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S105\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S106\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S107\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S108\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S109\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S110\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S111\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S112\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S113\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S114\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S115\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S116\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S117\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S118\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S119\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S120\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S121\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S122\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S124\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S125\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S126\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S127\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S128\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S129\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S130\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S131\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S132\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S133\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S134\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S135\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S136\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S137\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S138\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S139\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S147\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S148\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S149\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S151\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S154\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S155\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S156\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S157\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S158\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S160\\\\006', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S501\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S502\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S503\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S504\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S505\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S506\\\\001', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S895\\\\002', 'C:\\\\Rhea\\\\minor_project\\\\FACS\\\\S999\\\\001'] 593\n"
     ]
    }
   ],
   "source": [
    "# CODE TO OBTAIN PATHS CORRESPONDING TO FEATURE ACTION UNIT CODES OF EACH SEQUENCE\n",
    "\n",
    "lst = []\n",
    "lst1=[]\n",
    "#C:\\\\Users\\\\Harshit\\\\Downloads\\\\minor_project\\\\FACS\n",
    "for i in os.walk(\"C:\\\\Rhea\\\\minor_project\\\\FACS\"):\n",
    "    #print i\n",
    "    if i not in lst :\n",
    "        if(len(i[2])>0):\n",
    "            lst.append(str(i[0]) + \"\\\\\"+str(i[2][0]))\n",
    "        else:\n",
    "            #print i[0],i[1],i[2]\n",
    "            lst1.append(str(i[0])+\"\\\\\"+str(i[1][0]))\n",
    "            \n",
    "print lst1, len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 38, 39, 43, 44, 45, 54, 61, 62, 63, 64] 39\n"
     ]
    }
   ],
   "source": [
    "# CODE TO FIND OUT ALL THE ACTION-UNITS AVAILABLE IN DATASET\n",
    "\n",
    "dic={}\n",
    "for i in range(1,65):\n",
    "    if i not in dic:\n",
    "        dic[i]=0\n",
    "for x in lst:\n",
    "    with open(x) as f:\n",
    "        lines = f.read().split()\n",
    "        for i in range(0,len(lines)-1,2):\n",
    "            dic[int(float(lines[i]))]+=1\n",
    "au_nos = []\n",
    "for a in dic.keys():\n",
    "    if dic[a] > 0:\n",
    "        au_nos.append(a)\n",
    "\n",
    "print au_nos, len(au_nos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 327\n",
      "['C:\\\\Rhea\\\\minor_project\\\\Emotion\\\\S010\\\\001\\\\S010_001_00000014_emotion.txt', 'C:\\\\Rhea\\\\minor_project\\\\Emotion\\\\S010\\\\003\\\\S010_003_00000018_emotion.txt', 'C:\\\\Rhea\\\\minor_project\\\\Emotion\\\\S010\\\\005\\\\S010_005_00000016_emotion.txt']\n"
     ]
    }
   ],
   "source": [
    "# CODE TO ACCESS EMOTION LABELS OF ALL SEQUENCES: UNLABELED SEQUENCES ARE TREATED AS TEST CASES\n",
    "\n",
    "# dic={1:0,2:0,4:0,5:0,6:0,7:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0,16:0,17:0,18:0,20:0,21:0,23:0,24:0,25:0,26:0,27:0,28:0,\n",
    "#      29:0,31:0,34:0,38:0,39:0,43:0,45:0}\n",
    "\n",
    "ctr = 0\n",
    "training = []\n",
    "test = []\n",
    "cnt=0\n",
    "test_pics = []\n",
    "for x in lst:\n",
    "    dic={}\n",
    "    for i in range(1,65):\n",
    "        if i not in dic:\n",
    "            dic[i]=0\n",
    "    with open(x) as f:\n",
    "        flag=0\n",
    "        y=string.replace(x,\"FACS\",\"Emotion\")\n",
    "        y=string.replace(y,\"facs\",\"emotion\")\n",
    "        try:\n",
    "            with open(y) as emo:\n",
    "                e=emo.read()\n",
    "                e=int(float(e))\n",
    "                #print e\n",
    "        except:\n",
    "            flag=1\n",
    "            test_pics.append(y)\n",
    "            \n",
    "        lines = f.read().split()\n",
    "        for i in range(0,len(lines)-1,2):\n",
    "            y = 1 if (int(float(lines[i+1]))==0) else int(float(lines[i+1]))\n",
    "            dic[int(float(lines[i]))]+=y\n",
    "    features = []\n",
    "    #print dic.values()\n",
    "    for a in au_nos:\n",
    "        features.append(dic[a])\n",
    "    #print features\n",
    "    if(flag==0):\n",
    "        training.append([features, e])\n",
    "    else:\n",
    "        test.append([features, 0])\n",
    "\n",
    "print len(test_pics), len(training)\n",
    "print test_pics[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66L, 2L) (66L, 2L) (65L, 2L) (65L, 2L) (65L, 2L)\n",
      "45\n",
      "(65L, 2L) (65L, 2L) (66L, 2L) (66L, 2L) (65L, 2L)\n",
      "18\n",
      "(65L, 2L) (66L, 2L) (66L, 2L) (65L, 2L) (65L, 2L)\n",
      "59\n",
      "(66L, 2L) (66L, 2L) (65L, 2L) (65L, 2L) (65L, 2L)\n",
      "25\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# SAMPLES OF EACH EMOTION SEPARATED INTO 5 FOLDS EACH SUCH THAT EACH FOLD MAINTAINS THE SAME DISTRIBUTION AS THE ENIRE DATASET. \n",
    "\n",
    "all_folds = []\n",
    "all_emos = []\n",
    "\n",
    "#ANGER: {(57, 9), (57, 9), (56, 9), (56, 9), (56, 9)}\n",
    "y = 0\n",
    "pos = []\n",
    "neg = []\n",
    "an_test = []\n",
    "\n",
    "for x in training:\n",
    "    if x[-1]!=1:\n",
    "        neg.append([x[0],0])\n",
    "    else:\n",
    "        pos.append([x[0],1])\n",
    "        y += 1\n",
    "\n",
    "an_test.append(np.array(neg[:57]+ pos[:9]))\n",
    "an_test.append(np.array(neg[57:114]+ pos[9:18]))\n",
    "an_test.append(np.array(neg[114:170]+ pos[18:27]))\n",
    "an_test.append(np.array(neg[170:226]+ pos[27:36]))\n",
    "an_test.append(np.array(neg[226:282]+ pos[36:45]))\n",
    "an_test = np.array(an_test)\n",
    "print  an_test[0].shape, an_test[1].shape, an_test[2].shape, an_test[3].shape, an_test[4].shape\n",
    "print y\n",
    "all_folds.append(an_test)\n",
    "all_emos.append(pos+neg)\n",
    "\n",
    "#CONTEMPT: {(62 ,3), (62 ,3), (62 ,4), (62 ,4), (61 ,4)}\n",
    "y = 0\n",
    "pos = []\n",
    "neg = []\n",
    "an_test = []\n",
    "\n",
    "for x in training:\n",
    "    if x[-1]!=2:\n",
    "        neg.append([x[0],0])\n",
    "    else:\n",
    "        pos.append([x[0],1])\n",
    "        y += 1\n",
    "\n",
    "an_test.append(np.array(pos[:3]+ neg[:62]))\n",
    "an_test.append(np.array(pos[3:6]+ neg[62:124]))\n",
    "an_test.append(np.array(pos[6:10]+ neg[124:186]))\n",
    "an_test.append(np.array(pos[10:14]+ neg[186:248]))\n",
    "an_test.append(np.array(pos[14:18]+ neg[248:309]))\n",
    "an_test = np.array(an_test)\n",
    "print  an_test[0].shape, an_test[1].shape, an_test[2].shape, an_test[3].shape, an_test[4].shape\n",
    "print y\n",
    "all_folds.append(an_test)\n",
    "all_emos.append(pos+neg)\n",
    "\n",
    "\n",
    "#DISGUST: {(54 ,11), (54 ,12), (54 ,12), (53 ,12), (53 ,12)}\n",
    "y = 0\n",
    "pos = []\n",
    "neg = []\n",
    "an_test = []\n",
    "for x in training:\n",
    "    if x[-1]!=3:\n",
    "        neg.append([x[0],0])\n",
    "    else:\n",
    "        pos.append([x[0],1])\n",
    "        y += 1\n",
    "an_test.append(np.array(pos[:11]+ neg[:54]))\n",
    "an_test.append(np.array(pos[11:23]+ neg[54:108]))\n",
    "an_test.append(np.array(pos[23:35]+ neg[108:162]))\n",
    "an_test.append(np.array(pos[35:47]+ neg[162:215]))\n",
    "an_test.append(np.array(pos[47:59]+ neg[215:268]))\n",
    "an_test = np.array(an_test)\n",
    "print  an_test[0].shape, an_test[1].shape, an_test[2].shape, an_test[3].shape, an_test[4].shape\n",
    "print y\n",
    "all_emos.append(pos+neg)\n",
    "all_folds.append(an_test)\n",
    "\n",
    "\n",
    "#FEAR: {(61 ,5), (61 ,5), (60 ,5), (60 ,5), (60 ,5)}\n",
    "y = 0\n",
    "pos = []\n",
    "neg = []\n",
    "an_test = []\n",
    "for x in training:\n",
    "    if x[-1]!=4:\n",
    "        neg.append([x[0],0])\n",
    "    else:\n",
    "        pos.append([x[0],1])\n",
    "        y += 1\n",
    "\n",
    "an_test.append(np.array(pos[:5]+ neg[:61]))\n",
    "an_test.append(np.array(pos[5:10]+ neg[61:122]))\n",
    "an_test.append(np.array(pos[10:15]+ neg[122:182]))\n",
    "an_test.append(np.array(pos[15:20]+ neg[182:242]))\n",
    "an_test.append(np.array(pos[20:25]+ neg[242:302]))\n",
    "an_test = np.array(an_test)\n",
    "print  an_test[0].shape, an_test[1].shape, an_test[2].shape, an_test[3].shape, an_test[4].shape\n",
    "print y\n",
    "all_emos.append(pos+neg)\n",
    "all_folds.append(an_test)\n",
    "print len(all_emos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65L, 2L) (65L, 2L) (66L, 2L) (66L, 2L) (65L, 2L)\n",
      "69\n",
      "(65L, 2L) (66L, 2L) (66L, 2L) (65L, 2L) (65L, 2L)\n",
      "28\n",
      "(65L, 2L) (66L, 2L) (66L, 2L) (65L, 2L) (65L, 2L)\n",
      "83\n",
      "(7L, 327L, 2L) (7L, 5L)\n"
     ]
    }
   ],
   "source": [
    "# SAMPLES OF EACH EMOTION SEPARATED INTO 5 FOLDS EACH SUCH THAT EACH FOLD MAINTAINS THE SAME DISTRIBUTION AS THE ENIRE DATASET. \n",
    "\n",
    "#HAPPY: {(51 ,14), (51 ,14), (52 ,14), (52 ,14), (52 ,13)}\n",
    "y = 0\n",
    "pos = []\n",
    "neg = []\n",
    "an_test = []\n",
    "for x in training:\n",
    "    if x[-1]!=5:\n",
    "        neg.append([x[0],0])\n",
    "    else:\n",
    "        pos.append([x[0],1])\n",
    "        y += 1\n",
    "        \n",
    "an_test.append(np.array(pos[:14]+ neg[:51]))\n",
    "an_test.append(np.array(pos[14:28]+ neg[51:102]))\n",
    "an_test.append(np.array(pos[28:42]+ neg[102:154]))\n",
    "an_test.append(np.array(pos[42:56]+ neg[154:206]))\n",
    "an_test.append(np.array(pos[56:69]+ neg[206:258]))\n",
    "an_test = np.array(an_test)\n",
    "print  an_test[0].shape, an_test[1].shape, an_test[2].shape, an_test[3].shape, an_test[4].shape\n",
    "print y\n",
    "all_emos.append(pos+neg)\n",
    "all_folds.append(an_test)\n",
    "\n",
    "\n",
    "#SADNESS: {(59 ,6), (60 ,6), (60 ,6), (60 ,5), (60 ,5)}\n",
    "y = 0\n",
    "pos = []\n",
    "neg = []\n",
    "an_test = []\n",
    "for x in training:\n",
    "    if x[-1]!=6:\n",
    "        neg.append([x[0],0])\n",
    "    else:\n",
    "        pos.append([x[0],1])\n",
    "        y += 1\n",
    "an_test.append(np.array(pos[:6]+ neg[:59]))\n",
    "an_test.append(np.array(pos[6:12]+ neg[59:119]))\n",
    "an_test.append(np.array(pos[12:18]+ neg[119:179]))\n",
    "an_test.append(np.array(pos[18:23]+ neg[179:239]))\n",
    "an_test.append(np.array(pos[23:28]+ neg[239:299]))\n",
    "an_test = np.array(an_test)\n",
    "print  an_test[0].shape, an_test[1].shape, an_test[2].shape, an_test[3].shape, an_test[4].shape\n",
    "print y\n",
    "all_emos.append(pos+neg)\n",
    "all_folds.append(an_test)\n",
    "\n",
    "#SURPRISE: {(48 ,17), (49 ,17), (49 ,17), (49 ,16), (49 ,16)}\n",
    "y = 0\n",
    "pos = []\n",
    "neg = []\n",
    "an_test = []\n",
    "for x in training:\n",
    "    if x[-1]!=7:\n",
    "        neg.append([x[0],0])\n",
    "    else:\n",
    "        pos.append([x[0],1])\n",
    "        y += 1\n",
    "\n",
    "an_test.append(np.array(pos[:17]+ neg[:48]))\n",
    "an_test.append(np.array(pos[17:34]+ neg[48:97]))\n",
    "an_test.append(np.array(pos[34:51]+ neg[97:146]))\n",
    "an_test.append(np.array(pos[51:67]+ neg[146:195]))\n",
    "an_test.append(np.array(pos[67:83]+ neg[195:244]))\n",
    "an_test = np.array(an_test)\n",
    "print  an_test[0].shape, an_test[1].shape, an_test[2].shape, an_test[3].shape, an_test[4].shape\n",
    "print y\n",
    "all_emos.append(pos+neg)\n",
    "all_folds.append(an_test)\n",
    "\n",
    "all_folds = np.array(all_folds)\n",
    "all_emos = np.array(all_emos)\n",
    "\n",
    "print all_emo.shape, all_folds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "66 261\n",
      "Errors on training data are:  18\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.9393939394\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  18\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.4242424242\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "65 262\n",
      "Errors on training data are:  13\n",
      "Errors on testing data are:  7\n",
      "Accuracy here = 89.2307692308\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  18\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.8461538462\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  17\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.3076923077\n",
      "\n",
      "For this emotion, accuracy is 92.3496503497\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  15\n",
      "Errors on testing data are:  3\n",
      "Accuracy here = 95.3846153846\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "65 262\n",
      "Errors on training data are:  15\n",
      "Errors on testing data are:  3\n",
      "Accuracy here = 95.3846153846\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  14\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.9393939394\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "66 261\n",
      "Errors on training data are:  14\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.9393939394\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  14\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.8461538462\n",
      "\n",
      "For this emotion, accuracy is 94.4988344988\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  23\n",
      "Errors on testing data are:  6\n",
      "Accuracy here = 90.7692307692\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  23\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.4242424242\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  26\n",
      "Errors on testing data are:  3\n",
      "Accuracy here = 95.4545454545\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  22\n",
      "Errors on testing data are:  6\n",
      "Accuracy here = 90.7692307692\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  17\n",
      "Errors on testing data are:  10\n",
      "Accuracy here = 84.6153846154\n",
      "\n",
      "For this emotion, accuracy is 90.8065268065\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "66 261\n",
      "Errors on training data are:  13\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.4242424242\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  13\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.4242424242\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "65 262\n",
      "Errors on training data are:  14\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.8461538462\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  14\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.8461538462\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  17\n",
      "Errors on testing data are:  0\n",
      "Accuracy here = 100.0\n",
      "\n",
      "For this emotion, accuracy is 94.5081585082\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  51\n",
      "Errors on testing data are:  14\n",
      "Accuracy here = 78.4615384615\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "65 262\n",
      "Errors on training data are:  52\n",
      "Errors on testing data are:  13\n",
      "Accuracy here = 80.0\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  52\n",
      "Errors on testing data are:  13\n",
      "Accuracy here = 80.303030303\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "66 261\n",
      "Errors on training data are:  51\n",
      "Errors on testing data are:  14\n",
      "Accuracy here = 78.7878787879\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  54\n",
      "Errors on testing data are:  11\n",
      "Accuracy here = 83.0769230769\n",
      "\n",
      "For this emotion, accuracy is 80.1258741259\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  17\n",
      "Errors on testing data are:  6\n",
      "Accuracy here = 90.7692307692\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  17\n",
      "Errors on testing data are:  6\n",
      "Accuracy here = 90.9090909091\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  18\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.4242424242\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  19\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.3076923077\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  21\n",
      "Errors on testing data are:  2\n",
      "Accuracy here = 96.9230769231\n",
      "\n",
      "For this emotion, accuracy is 92.6666666667\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  52\n",
      "Errors on testing data are:  14\n",
      "Accuracy here = 78.4615384615\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  53\n",
      "Errors on testing data are:  13\n",
      "Accuracy here = 80.303030303\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  52\n",
      "Errors on testing data are:  14\n",
      "Accuracy here = 78.7878787879\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  50\n",
      "Errors on testing data are:  16\n",
      "Accuracy here = 75.3846153846\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  59\n",
      "Errors on testing data are:  11\n",
      "Accuracy here = 83.0769230769\n",
      "\n",
      "For this emotion, accuracy is 79.2027972028\n",
      "\n",
      "\n",
      "For a 3 degree polynomial as kernel function, accuracy is: 89.1655011655\n"
     ]
    }
   ],
   "source": [
    "# SEVEN DIFFERENT CLASSIFIERS FOR EACH EMOTION ARE MADE, IN KEEPING WITH THE PROPERTY OF ONE VS REST CLASSIFICATION.\n",
    "# EACH CLASSIFIER IN TURN IS CROSS VALIDATED USING K (=5) DIFFERENT CLASSIFIERS.\n",
    "# A POLYNOMIAL OF DEGREE 3 IS USED AS A KERNEL FUNCTION\n",
    "\n",
    "accu = 0.0\n",
    "for emo in all_folds:\n",
    "    #emo = all_folds[0] \n",
    "    tot_accu = 0.0\n",
    "    print '\\n------------------------NEXT EMOTION-------------------------------\\n'\n",
    "    for i in range(0, 5):\n",
    "        print '\\nWorking on fold #'+str(i) + ' as testing data'\n",
    "        \n",
    "        test_feat = []\n",
    "        test_targ = []\n",
    "\n",
    "        for o in emo[i]:\n",
    "            test_feat.append(o[0])\n",
    "            test_targ.append(o[1])\n",
    "\n",
    "        train_feat = []\n",
    "        train_targ = []\n",
    "\n",
    "        for j in range(0, 5):\n",
    "            if j != i:\n",
    "                for o in emo[j]:\n",
    "                    train_feat.append(o[0])\n",
    "                    train_targ.append(o[1])           \n",
    "\n",
    "        print len(test_feat), len(train_feat)\n",
    "\n",
    "        clf = svm.SVC(kernel='poly', degree=3, C=C).fit(np.array(train_feat), np.array(train_targ)) #osumz\n",
    "        \n",
    "        #Checking on training data, i.e the single folds of data\n",
    "        errors1 = 0\n",
    "        Z = clf.predict(train_feat)\n",
    "        \n",
    "        for i in range(0, len(Z)):\n",
    "            if (Z[i] != train_targ[i]):\n",
    "                errors1 += 1\n",
    "                \n",
    "        print \"Errors on training data are: \", errors1\n",
    "        \n",
    "        #Checking on testing data, i.e k-1 folds of data\n",
    "        errors2 = 0\n",
    "        Z = clf.predict(test_feat)\n",
    "        \n",
    "        for i in range(0, len(Z)):\n",
    "            if (Z[i] != test_targ[i]):\n",
    "                errors2 += 1\n",
    "        print \"Errors on testing data are: \", errors2\n",
    "        fold_accu = 100.00 - float(errors2*100.00)/len(test_targ)\n",
    "        tot_accu += fold_accu\n",
    "        print \"Accuracy here = \" + str(fold_accu)\n",
    "        \n",
    "    tot_accu /= 5\n",
    "    print '\\nFor this emotion, accuracy is ' + str(tot_accu)\n",
    "    accu += tot_accu\n",
    "        \n",
    "accu /= 7\n",
    "print '\\n\\nFor a 3 degree polynomial as kernel function, accuracy is: ' + str(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  8\n",
      "Accuracy here = 87.8787878788\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  6\n",
      "Accuracy here = 90.9090909091\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  7\n",
      "Accuracy here = 89.2307692308\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  9\n",
      "Accuracy here = 86.1538461538\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  6\n",
      "Accuracy here = 90.7692307692\n",
      "\n",
      "For this emotion, accuracy is 88.9883449883\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  1\n",
      "Errors on testing data are:  3\n",
      "Accuracy here = 95.3846153846\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "65 262\n",
      "Errors on training data are:  1\n",
      "Errors on testing data are:  2\n",
      "Accuracy here = 96.9230769231\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  1\n",
      "Errors on testing data are:  1\n",
      "Accuracy here = 98.4848484848\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  2\n",
      "Accuracy here = 96.9696969697\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  0\n",
      "Accuracy here = 100.0\n",
      "\n",
      "For this emotion, accuracy is 97.5524475524\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.8461538462\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  6\n",
      "Accuracy here = 90.9090909091\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  7\n",
      "Accuracy here = 89.3939393939\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  3\n",
      "Accuracy here = 95.3846153846\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  8\n",
      "Accuracy here = 87.6923076923\n",
      "\n",
      "For this emotion, accuracy is 91.4452214452\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.9393939394\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.4242424242\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.3076923077\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.8461538462\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.3076923077\n",
      "\n",
      "For this emotion, accuracy is 92.965034965\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  1\n",
      "Accuracy here = 98.4615384615\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  2\n",
      "Accuracy here = 96.9230769231\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  2\n",
      "Accuracy here = 96.9696969697\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.9393939394\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  6\n",
      "Accuracy here = 90.7692307692\n",
      "\n",
      "For this emotion, accuracy is 95.4125874126\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.8461538462\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.9393939394\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.9393939394\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  3\n",
      "Accuracy here = 95.3846153846\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.3076923077\n",
      "\n",
      "For this emotion, accuracy is 93.8834498834\n",
      "\n",
      "------------------------NEXT EMOTION-------------------------------\n",
      "\n",
      "\n",
      "Working on fold #0 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  2\n",
      "Accuracy here = 96.9230769231\n",
      "\n",
      "Working on fold #1 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  5\n",
      "Accuracy here = 92.4242424242\n",
      "\n",
      "Working on fold #2 as testing data\n",
      "66 261\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  4\n",
      "Accuracy here = 93.9393939394\n",
      "\n",
      "Working on fold #3 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  1\n",
      "Accuracy here = 98.4615384615\n",
      "\n",
      "Working on fold #4 as testing data\n",
      "65 262\n",
      "Errors on training data are:  0\n",
      "Errors on testing data are:  7\n",
      "Accuracy here = 89.2307692308\n",
      "\n",
      "For this emotion, accuracy is 94.1958041958\n",
      "\n",
      "\n",
      "For a 3 degree polynomial as kernel function, accuracy is: 93.4918414918\n"
     ]
    }
   ],
   "source": [
    "# SEVEN DIFFERENT CLASSIFIERS FOR EACH EMOTION ARE MADE, IN KEEPING WITH THE PROPERTY OF ONE VS REST CLASSIFICATION.\n",
    "# EACH CLASSIFIER IN TURN IS CROSS VALIDATED USING K (=5) DIFFERENT CLASSIFIERS.\n",
    "# A POLYNOMIAL OF DEGREE 3 IS USED AS A KERNEL FUNCTION\n",
    "\n",
    "accu = 0.0\n",
    "for emo in all_folds:\n",
    "    #emo = all_folds[0] \n",
    "    tot_accu = 0.0\n",
    "    print '\\n------------------------NEXT EMOTION-------------------------------\\n'\n",
    "    for i in range(0, 5):\n",
    "        print '\\nWorking on fold #'+str(i) + ' as testing data'\n",
    "        \n",
    "        test_feat = []\n",
    "        test_targ = []\n",
    "\n",
    "        for o in emo[i]:\n",
    "            test_feat.append(o[0])\n",
    "            test_targ.append(o[1])\n",
    "\n",
    "        train_feat = []\n",
    "        train_targ = []\n",
    "\n",
    "        for j in range(0, 5):\n",
    "            if j != i:\n",
    "                for o in emo[j]:\n",
    "                    train_feat.append(o[0])\n",
    "                    train_targ.append(o[1])           \n",
    "\n",
    "        print len(test_feat), len(train_feat)\n",
    "\n",
    "        clf = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(np.array(train_feat), np.array(train_targ)) #osumz\n",
    "        \n",
    "        #Checking on training data, i.e the single folds of data\n",
    "        errors1 = 0\n",
    "        Z = clf.predict(train_feat)\n",
    "        \n",
    "        for i in range(0, len(Z)):\n",
    "            if (Z[i] != train_targ[i]):\n",
    "                errors1 += 1\n",
    "                \n",
    "        print \"Errors on training data are: \", errors1\n",
    "        \n",
    "        #Checking on testing data, i.e k-1 folds of data\n",
    "        errors2 = 0\n",
    "        Z = clf.predict(test_feat)\n",
    "        \n",
    "        for i in range(0, len(Z)):\n",
    "            if (Z[i] != test_targ[i]):\n",
    "                errors2 += 1\n",
    "        print \"Errors on testing data are: \", errors2\n",
    "        fold_accu = 100.00 - float(errors2*100.00)/len(test_targ)\n",
    "        tot_accu += fold_accu\n",
    "        print \"Accuracy here = \" + str(fold_accu)\n",
    "        \n",
    "    tot_accu /= 5\n",
    "    print '\\nFor this emotion, accuracy is ' + str(tot_accu)\n",
    "    accu += tot_accu\n",
    "        \n",
    "accu /= 7\n",
    "print '\\n\\nFor a 3 degree polynomial as kernel function, accuracy is: ' + str(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected was: 5  Result is: 7\n",
      "Expected was: 3  Result is: 7\n",
      "Expected was: 1  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 3  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 3  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 4  Result is: 7\n",
      "Expected was: 3  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 1  Result is: 7\n",
      "Expected was: 1  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 3  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 1  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 4  Result is: 7\n",
      "Expected was: 5  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 1  Result is: 7\n",
      "Expected was: 4  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 1  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 1  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 1  Result is: 3\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 4  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "Expected was: 6  Result is: 7\n",
      "Expected was: 2  Result is: 7\n",
      "82.5688073394\n"
     ]
    }
   ],
   "source": [
    "# CHECKING FOR ONE VS ONE PERFORMANCE OF SVM ON TRAINING DATA USING A 3:1 DIVISION\n",
    "\n",
    "emoss = [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "x = int(3.0*327.0/4.0)\n",
    "\n",
    "for t in training[:x]:\n",
    "    train_data.append(t[0])\n",
    "    train_labels.append(t[1])\n",
    "\n",
    "clf = svm.SVC(kernel='poly', degree=3,  C=C).fit(np.array(train_data), np.array(train_labels))\n",
    "err = 0.0\n",
    "\n",
    "for t in training[x:]:\n",
    "    \n",
    "    testt = np.array(t[0]).reshape(1, -1)\n",
    "    res = clf.predict(testt)\n",
    "    \n",
    "    if res[0] != t[1]:\n",
    "        err += 1\n",
    "        print 'Expected was: '+str(t[1]) + '  Result is: ' + str(res[0])\n",
    "\n",
    "accuracy = 100.00 - float(err/3.27)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# CODE TO CHECK FOR THE PREDICTIONS MADE BY THE CLASSIFIERS FOR TEST DATA SET USING ONE VS REST APPROACH.\n",
    "# IF LABEL IS NOT FOUND, SAMPLE IS LABELED NEUTRAL.\n",
    "\n",
    "emoss = [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "def classifyy(feat_set):\n",
    "    '''\n",
    "    Uses ORing of results of k (=5) different cross validated classifiers. \n",
    "    Only a value of 1 is treated as a positive result for that particular emotion.\n",
    "    '''\n",
    "    emos_predicted = []\n",
    "    for no,emo in enumerate(all_folds):\n",
    "        val = False\n",
    "        \n",
    "        for i in range(0, 5):\n",
    "            \n",
    "            train_feat = []\n",
    "            train_targ = []\n",
    "\n",
    "            for j in range(0, 5):\n",
    "                if j != i:\n",
    "                    for o in emo[j]:\n",
    "                        train_feat.append(o[0])\n",
    "                        train_targ.append(o[1])           \n",
    "\n",
    "            clf = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(np.array(train_feat), np.array(train_targ))  #osumz\n",
    "\n",
    "            z = clf.predict(feat_set)\n",
    "            val = val + z[0]\n",
    "        \n",
    "        if val:\n",
    "            emos_predicted.append(emoss[no])\n",
    "\n",
    "    return emos_predicted\n",
    "\n",
    "\n",
    "n = 0\n",
    "for k in range(0, len(test)):\n",
    "\n",
    "    t = test[k]\n",
    "    to_classify = np.array(t[0]).reshape(1, -1)\n",
    "    result = classifyy(to_classify)\n",
    "#     if (len(result) > 0):\n",
    "#         #print test_pics[k][:38], result\n",
    "#     else:\n",
    "        #print test_pics[k][:38], 'neutral'\n",
    "    \n",
    "    if (len(result) > 1):\n",
    "        n += 1\n",
    "        \n",
    "print n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len('C:\\\\Rhea\\\\minor_project\\\\Emotion\\\\S010\\\\001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
